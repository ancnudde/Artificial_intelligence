{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:458: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:459: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:460: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:461: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:462: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:465: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from utils import uniprotRetrieve\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf #Make sure version 1.3.0 is installed\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def cdhit(inputFastaFile, identity=0.9, outputDir=\"\"):\n",
    "    if outputDir and not os.path.exists(outputDir):\n",
    "        os.makedirs(outputDir)\n",
    "    outputFile=inputFastaFile.split(\"/\")[-1].replace(\".fasta\",\"_cdhit.fasta\")\n",
    "    outputFilePath=\"{}{}\".format(outputDir,outputFile)\n",
    "    command = \"cd-hit -i {} -o {} -c {}  -n 3 -M 1500\".format(inputFastaFile,outputFilePath,identity)\n",
    "    cmd = subprocess.Popen(command,\n",
    "                           shell=True,\n",
    "                           stdin=subprocess.PIPE,\n",
    "                          stdout=subprocess.PIPE,\n",
    "                          stderr=subprocess.STDOUT)\n",
    "    cmd.communicate()\n",
    "    return outputFilePath\n",
    "\n",
    "\"\"\" Read in model to generate Unirep vectors\"\"\"\n",
    "# Sync relevant weight files\n",
    "!aws s3 sync --no-sign-request --quiet s3://unirep-public/64_weights/ 64_weights/\n",
    "    \n",
    "# Import the mLSTM babbler model\n",
    "from unirep import babbler64 as babbler\n",
    "\n",
    "# Where model weights are stored.\n",
    "MODEL_WEIGHT_PATH = \"./64_weights\"\n",
    "\n",
    "batch_size = 12\n",
    "b = babbler(batch_size=batch_size, model_path=MODEL_WEIGHT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1. Cytoplasmic proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Download sequences and identifiers\"\"\"\n",
    "QUERY=\"taxonomy:Gammaproteobacteria (locations:(location:cytoplasm) OR locations:(location:cytosol)) NOT annotation:(type:signal)\"\n",
    "FORMAT=\"tab\"\n",
    "FILENAME=\"cytoplasm.tab\"\n",
    "COLUMNS=\"id,sequence\"\n",
    "uniprotRetrieve(FILENAME, format=FORMAT, query=QUERY, columns=COLUMNS)\n",
    "\n",
    "CYTOPLASM = pd.read_csv(FILENAME,sep=\"\\t\")\n",
    "# Write fasta file \n",
    "fastaFile = open(\"cytoplasm.fasta\",\"w\")\n",
    "for i,row in tqdm(CYTOPLASM.iterrows()):\n",
    "    entry = row[\"Entry\"]\n",
    "    sequence = row[\"Sequence\"]\n",
    "    fastaFile.write(\">{}\\n{}\\n\".format(entry,sequence))\n",
    "fastaFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Use cdhit to obtain dataset of no more than 50 percent sequences identit \"\"\"\n",
    "CYTOPLASM_CDHIT = cdhit(\"cytoplasm.fasta\",identity=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Periplasmic proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY=\"taxonomy:Gammaproteobacteria locations:(location:periplasm) annotation:(type:signal)\"\n",
    "FORMAT=\"tab\"\n",
    "FILENAME=\"periplasm.tab\"\n",
    "COLUMNS=\"id,sequence,feature(SIGNAL)\"\n",
    "uniprotRetrieve(FILENAME, format=FORMAT, query=QUERY, columns=COLUMNS)\n",
    "\n",
    "PERIPLASM = pd.read_csv(FILENAME,sep=\"\\t\")\n",
    "PERIPLASM[\"newStart\"]=PERIPLASM[\"Signal peptide\"].apply(lambda x : int(x.split(\";\")[0].split(\"..\")[-1]))\n",
    "# Write fasta file with and without fasta \n",
    "withSP = open(\"periplasm_with_sp.fasta\",\"w\")\n",
    "withoutSP = open(\"periplasm_without_sp.fasta\",\"w\")\n",
    "for i,row in tqdm(PERIPLASM.iterrows()):\n",
    "    entry = row[\"Entry\"]\n",
    "    sequence = row[\"Sequence\"]\n",
    "    newStart = row[\"newStart\"]\n",
    "    withSP.write(\">{}\\n{}\\n\".format(entry,sequence))\n",
    "    withoutSP.write(\">{}\\n{}\\n\".format(entry,sequence[newStart:]))\n",
    "withSP.close()\n",
    "withoutSP.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Use cdhit to obtain dataset of no more than 50 percent sequences identity (without SP) \"\"\"\n",
    "PERIPLASM_WITHOUT_SP_CDHIT = cdhit(\"periplasm_without_sp.fasta\",identity=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Use cdhit to obtain dataset of no more than 50 percent sequences identity (with SP) \"\"\"\n",
    "PERIPLASM_WITH_SP_CDHIT = cdhit(\"periplasm_with_sp.fasta\",identity=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Generate unirep vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 3457\n",
      "2 / 3457\n",
      "3 / 3457\n",
      "4 / 3457\n",
      "5 / 3457\n",
      "6 / 3457\n",
      "7 / 3457\n",
      "8 / 3457\n",
      "9 / 3457\n",
      "10 / 3457\n",
      "11 / 3457\n",
      "12 / 3457\n",
      "13 / 3457\n",
      "14 / 3457\n",
      "15 / 3457\n",
      "16 / 3457\n",
      "17 / 3457\n",
      "18 / 3457\n",
      "19 / 3457\n",
      "20 / 3457\n",
      "21 / 3457\n",
      "22 / 3457\n",
      "23 / 3457\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Generate vectors for periplamic proteins without SP \"\"\"\n",
    "\n",
    "with open(\"periplasm_without_sp_cdhit.fasta\") as f:\n",
    "    lines = [line.strip() for line in f.readlines()]\n",
    "\n",
    "periplasm=dict()\n",
    "for line in lines:\n",
    "    if line.startswith(\">\"):\n",
    "        ID = line.replace(\">\",\"\")\n",
    "        periplasm[ID]=dict()\n",
    "        periplasm[ID][\"seq\"]=\"\"\n",
    "    else:\n",
    "        periplasm[ID][\"seq\"]+=line\n",
    "\n",
    "FILE=\"periplasm_without_sp.unirep\"\n",
    "if not os.path.exists(FILE):\n",
    "    with open(FILE, 'w'): pass      \n",
    "\n",
    "with open(FILE) as f:\n",
    "    IDS_DONE = [LINE.strip().replace(\">\",\"\") for LINE in f.readlines() if LINE.startswith(\">\")]\n",
    "IDS_TODO = [ID for ID in periplasm.keys() if ID not in IDS_DONE]\n",
    "\n",
    "total = len(IDS_TODO)\n",
    "i=1\n",
    "for ID in IDS_TODO:\n",
    "    seq = periplasm[ID][\"seq\"]\n",
    "    repres = b.get_rep(seq)\n",
    "    #periplasm[ID][\"unirep\"]= repres\n",
    "    print(i,\"/\",total)\n",
    "    i+=1\n",
    "    with open(FILE,\"ab\") as f:\n",
    "        f.write(bytes(\">\"+ID+\"\\n\", 'utf-8'))\n",
    "        np.savetxt(f,repres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

